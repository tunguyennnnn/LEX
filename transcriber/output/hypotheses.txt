hello everybody yeah good week we have a good crowd for Johns the second talk it's very exciting so the first year that at %HESITATION John will be talking twice %HESITATION couple things too %HESITATION and to know John a talker for about an hour or so and it will have thirty minutes for questions the Mike is right there so it's right there and %HESITATION us a disk the line up %HESITATION when we get to the questions try to keep your questions on what John talked about if you get up and ask when doom force come out I'm gonna kick you in the knee so right there %HESITATION so %HESITATION I will %HESITATION not we see more time but you guys in the back because John can write on the board and we have plenty indie seats here you can file and it's you know don't worry that there's reserve seats there's go and sit in on %HESITATION alright I will give you guys %HESITATION Mr karmic okay okay so I guess it's sort of like a school room fashion I deluded myself for a little while that this would be the first talk where I ever actually meet slides to present but you didn't actually come to pass so it's gonna be notes and talking and some scribbling on the board again so most almost all of what we do in game development is really more about art history it's about trying to appeal to people but there's the small section of the small section of what goes into the games that's drawing the pictures on the screen that you can at least make some ties to die you know the hardest of hard sciences and while you know it's great that people are researching the psychology in the different ways that people think about impulsion loops and from these other game design topics are the raw physics that goes into rendering I just kind of goes to the heart of physics where you know goes to the side of the all star list of physics with Newton's optics in Maxwell's equations in Einstein's relativity and it's kind of neat to think that this is sort of brought to bear in that the techniques that go into sort of making the games that we play so at the start at the start you think well okay we see lights so what actually is light and we've got a definition now that lights the sliver of the electromagnetic spectrum that we can actually perceive but that has a really long and complicated history for how we sort of reached that conclusion and how it's not really as clear cut as most people would like I would like it to be I you optical research started and all the way back with one of the Greek philosophers buy it and I've Newton did a whole lot of work with breaking light up with prison seeing how white light was actually composed of all the different colors of the spectrum had they had together to make what we perceive as light I and then for the wrist centuries long debate about whether light was a particle like this little tiny billiard ball these photons that you shoot out or a wave of fact like all the things you see and waves in water and weeds in matter so on and finally we reached the conclusion that well it's a wave particle duality of that quantum mechanics talks about and this is very unsatisfying when you begin looking at this I am but it's really pretty much irrefutable there these straightforward experiments that can be done to show they can look at it one way it's a way to look at it another way it's a light I or it's I a particle so luckily for computer graphics we hardly care at all about that only when you start looking at some aspects of surface reflectance models do you start caring at all about some these quantum mechanical properties of light for the most part we can look at life as zillions and zillions of little billiard balls of shot out from whites and bouncing off of things and eventually reaching our eyes so that we can perceive them I am there's a lot of simplifications that well that have to happen when you when you talk about simulating this the I there's a lot of engineering disciplines like thermal managements are radio engineering that do simulations of the electromagnetic spectrum just other parts of it how they they bounce around interact with things and this is done all the time and it works it really is science so you can say rendering an image or deciding how much like reaches a particular area is about as basic of a science as it comes there's not a any artistic measure in here there are tons of other aspects when she get into perception that do become questions about well maybe there is artistry that goes into producing something when you got an impression that you want but when you're talking about stimulating environment which most of what we do in some of the hard core FBS type games is we we are pretending that we've got this virtual world and we're running a camera through it and we're trying to simulate what's happening in various ways add nowadays we know what we would have to do to bake that almost perfect we just have no where near that the computing capacity to do I've really really high level simulation but we can trace its useful even if you're not going to do the right thing to at least understand what the right thing is and then understand which trade off you're making and make them with sort of a clear head rather than accidentally backing into trade offs that may or may not be really the best waited to go about things so so many that it took a long time for people to realize that these other phenomena things like radio waves and there's a lot of confusion in nineteenth and twentieth century physics about like which things were particles in which things were raised and we still have kind of mixed up terminology when you talk about cosmic rays that are actually particles and you talk about I know alpha radiation and beta radiation these things that are particle based rather than being raised from the electromagnetic spectrum but we use the stuff all the time for radio waves I feel your wifi as two gigahertz I in you know I've spent frequencies now beyond the visible light rays are up and I know the terror hurts rains many terrorists I am but there's basically the same thing they just differ in how they interact with matter they're produced in some what similar ways by the different things change they behave differently when they interact with other I based on their way flank is Y. X. rays can shoot through things radio waves can go through some things that invisible light pretty much bounces off so another important critical thing really is that photons bit little bundles of light that we talk about they are absolutely quantize again part of that the quantum weirdness that you can't send off this arbitrarily divisible amount but there is a an almost unbelievably large number of that given light that's throwing out is you know I can just see zillions with a straight face because it's a very large scientific notation number it's not trillions if not quite really needs it even more than that that are coming out in terms of the bundle I've quanta of energy I am now they do have characteristics to them if we treat them as little billiard balls and computer graphics we are generally looking at only a few different spectrums of a few different wavelengths in the spectrum of light and that has to do with an aspect of the human visual system while there are this incredibly divisible spectrum of light that goes out we're only susceptible to three sort of piles of white and they're not even individual frequencies that's why we can get by with red green and blue for I've for monitors innocent spectrums because we only have three types of color receptors in our eyes and I often think how it would be really interesting if you could look at all these other specter was bouncing around that's what thermal imaging in some of these other things like you sort of get a peek into it and that's only light that's very that's EM radiation it's very close to the visible spectrum the infrared I it's it would be much more bizarre and interesting to be able to visualize radio waves in a real time space to like see all the multi path that's causing your wifi to be weird in specific ways why you're moving something over here causes the yeah I know that the radiation you change so much at your intent to make a difference in your reception strength and these are all things that that have a bearing to what you do with light transport as well as other wave phenomena like audio might really really high end audio processing is the exact same thing as what we treat like processing I send out energy it bounces off of all sorts of things in the world and eventually arrives at something that's going to perceive it should be your ears in that case versus your eyes so to come to start with but the path of a photon of what it would take I you've got something creates that the photon ad for the longest time in our human existence about the only thing that we saw creating photons was a great deal of heat I you heat things up hot enough and photon start coming off of them heated up announced it starts glowing a dull red you heated up more it starts getting more yellow ation towards white as more and more of the colors of the spectrum are emitted from these I've %HESITATION hot things and obviously the sun is a very hot thing where you got a fusion reactor gelling and beyond the light that comes off of that is all of these are these Adams giving up some energy so photons carry energy away from Iowa where they came from and this is that radiative I radiative heat transfer where something gets hot if you leave it all by itself there it glows and eventually stops glowing it cools down going down to the spectrum getting cooler and cooler until you don't see any visible light because it's actually lost much of are on earth radiative heat transfer is the least effective form of heat transfer you get much more from conduction where just kind of goes through the actual physical contact I AM into other areas of the heat spreads out or convection where moving currents of air or water take the heat away but in space radiation is the only way you lose heat and aerospace engineering this is extremely important things like that areas like the international space station and space ships they have to worry a whole lot about thermal management because the only tool they've really got his radiation you see you see these enormous solar panels where they collect solar energy but a lot of space vehicles have to have enormous radiators where they actually let the energy bill you know go out from the vehicle otherwise they would get hotter and hotter so the I it's important note that even if it's not glowing so that we can see it everything still radiating so you don't see the space station glowing red hot it's just going get whatever its normal temperature is which could be perceived with infrared sensors bloodied slowly loses energy and it eventually reaches a balance that's why something stuck out in the sun in space doesn't get hotter and hotter eventually it reaches the point where the light that's coming in and hitting yet is equaled by the radiation that's leaving yet and there are I like you can make now we've made rocket engines that are radiately cooled where they burn five thousand degrees or so inside and they get so blindingly white hot on the outside that all of the energy that's not going out the nozzle that soaking into the walls is radiated away as a whole lot of light and this is essentially what old style incandescent light bulbs were get a tungsten filament you made it really hot by pushing electrons through it and it got hot enough it started glowing and he watched closely it was a very like heavy filament you could watch it warm up for especially shut down it would go through and a ramp through the temperatures you would see it be read and get up to white hot and then when you shut it down it would cool down through yellow and then back to read before finally settling I settling back to radiating in non visible regions that sort of room temperature eventually nowadays we have a lot more efficient ways to create photons with five fluorescents and LEDs things that are tuned carefully to just barely knowledge B. I. the electrons in the Adams out to an excited state let them collapse back down and spit a photon out for the most part photon emission is random in terms of which direction it goes when you look at radio engineering there's huge bodies of literature for intended design that determine how you can make make it slightly stronger or weaker in different directions but they're still a very fundamental nature of randomness give the quantum mechanics aspect if there's added at a very low level natural events are completely random and you can't just say I only want photons that Accomack gonna come out of the left side of this material so you get a photon that pops off in some random direction I it may go straight for it it's coming from a distant star if you go straight for trillions of miles more or less just traveling through space there's little bits of general relativity without working of light that can happen but for the most part continue on indefinitely self propagating wave so pops off of some Adam somewhere maybe flies through space for a billion trillion miles or something comes in finally hits our earth's atmosphere and then start interacting with the atmosphere in some way every change in density that are visible light goes through will word out will result in it bending its path somewhat this is called refraction I the most obvious case when you look at it is things like prisms and lands is where you can feel like really strongly warped but it happens in any any sort of density change going from the vacuum of space to the outer reaches of our atmosphere and that every change in Italian pressure or temperature changes the density and that causes very slight subtle movements of diet changes in the direction of the light on this is actually why stars twinkle out at night if you're on a clear night and you see stars coming in from billions or trillions of miles away going completely straight till it hits the upper atmosphere and then it may slightly deviate just tiny fractions of degrees and this can cause the in the very small number of photons that you're seeing there to kind of come and go or move around in different ways are the most important thing for from a computer graphics standpoint are the effects that happen when it hits more solid matter solid surfaces or even liquid surfaces and that's where I it has the opportunity to to generally what it means even gas you can wind up having the case of absorbing the photon I am this happens rarely and gas you can pass through hundreds of miles of atmosphere and not have too many of the photons absorbed I've but it happens very rapidly and I in matter in solid matter I am the a typical photon when it hits a surface might penetrate a little bit into it a service like metal will bounce off of just the first several Adams it doesn't take many molecule or many atoms of I of metal before you could reflect light out which is why you can make the super enormous space mirrors that are just a very tiny sputtering of aluminum on some plastic film and they can actually make solar sails are giant solar collectors and concentrators but for most other materials the light can penetrate a little bit further into it I as it interacts with the molecules and it can either be absorbed raising the temperature a little bit high going into eventually I keep making it harder so that Sartre's radiating out radiating out at some level or a can redirect the photon in some way you got the minor re directions from the refraction and much stronger ones wanted Iraq's it bounces off of a solid surface there's a ton of different names there's literally a couple dozen different names for the different ways that light can interact with services there's all the different types of scattering refraction rift affliction refraction Todd reflection can be split up into specular reflection diffuse reflection and there's all sorts of different sub categories mean optics is a huge topic their societies dedicated to your every aspect of it and there's huge terminologies for all of it but for the most part you can say photon comes in and if it's not absorb its can be kicked out some other direction eidetic can go in Iraq potentially with the atmosphere or potentially with another surface and eventually it's either absorbed or actually it is absorbed somewhere but for the most part they're absorbed into services around us tiny tiny fraction of all the photons that are bouncing around eventually hits our eyes and even when it gets to our eyes which are mostly transparent there's this chance that the photon hits and it speculatively reflects off of our eye and you know it made it all the way out of the billions of possible traces made it to my eye and the decides to speculate really reflect off some other direction but most of it but it's the I. M. hits the lands gets through propagates through I victories in aqueous humor in all biological parts of the eye and hits receptors in the back of our eyeballs that turn those eventually into neural impulses that our brain works now our eyes can actually be quite sensitive they I the rods the non color sensitive part of our eyes when they're fully dark adapted if you've been staying outside for I in a dark area for twenty thirty minutes single photons can cause chemical reactions to happen in that I you know inside the rod sells it takes a handful of them a couple dozen for attorney do a neural impulses but it is possible for people that especially in the old days people watching for things on ships since I moonless nights that might be out all night with nothing but faint starlight you can have cases of just handfuls of photons coming off of something being registered and showing up and people ally knowledge in their existence which is pretty amazing when you think about these incredible subatomic particles ninety particles but incredible the scope of that being detectable biases biological entities and that there are limits to the head on what you can wind up detecting with white on a light house the visible light that we see has a wavelength and you can't really deal with things that are smaller than that which is why you're never going to have a real picture of an atom or molecule users are much much smaller than I know that the wavelengths of light I you eventually use electron microscopes and then scanning tunneling microscopes in these other things that don't deal with white at all to take those super tiny pictures like the other boy and his atom movie that IBM research did which was done with a little raster grid of of atoms which is really in the fundamental sense of the word deeply awesome that we are dealing with matter for the very constituents of everything at that level and we can make a little a little movie out of it I but those pictures have nothing to do with light nothing to do with rendering of diet and basically that the techniques that I'm talking about here that's a really different way of sensing what's going on at that level so I drew kept the the basic pictures of this you've got something a sign up here spits out some white travels through space gets to the atmosphere on the earth maybe bends a little bit maybe just go straight through comes down hits a surface maybe gets absorbed maybe hit something else got walls in rooms and bouncing around in there and eventually if we're seeing it reaches somebody's eyeball side and that's the physics of what happens it's really well understood it does come down to a lot of data acquisition and characterization when you talk about how died the critical interactions with the services you've got your basic theoretical thing if you talk about a flat surface you say like comes in what happens to it that's the question of surface response if you have a perfect mirror and it's worth noting that to be the I you don't have to be perfect on an atomic level to be a perfect mirror you only have to be perfect optical level which is somewhat larger so people can make basically perfect mirrors just highly highly polished things a perfect mirror will have the photon reflect off in this exact reflection you take the normal to the surface you wind up with equal angles so highly polished surfaces act like this I am when you get a a reflection off of something like the surface of water it'll behave like this but most of the services that we look around us do not behave like we have I spread of the energy where it comes in and it bounces off some degree in every direction no matter which way you look at most surfaces you see again zillions of photons coming in some of them go in every direction they just go in a direction that's biased based on the type of surface that it is a surface that I one of the easy things that a lot of times is approximated both in the engineering sciences and in computer graphics is to assume that the surface reflects perfectly diffusely or it's a land Bersham surface and what that means is that no matter which way the light comes in if it gets it completely edge on completely straight on it has it equal probability of going in every direction and there are some materials that are close to this if you take something like I've a block of chalk white chalk that behaves almost as a perfect diffuse reflector if you light it from one position and you look at that like a little scribe out area on it from any different area around it he will appear to have about the same amount of energy aiming out of it but there are I most all surfaces are more complex than that though most of them will say we've got like coming in here there will be more of it coming out around the reflection area and some general amount coming out in all different directions how but these can actually get quite complicated and the simplification that we use in graphic sort of approximate these but you can measure these with specific tools that go in and take lots of samples from moving the whites around because it depends I unfortunately this is one of the areas where does get I not so great for computer graphics it depends both on the incoming direction and the outcome in direction and those are two angles in each one so it winds up being a four dimensional equation to say how are light comes in here how does it come out in some other direction and if I do get worse than that because very few things do reflect just off of this upper surface most of the time the light will go we end go below the surface bounce around a little bit and shoot out some other direction so if you're saying well I photon comes in here not only do you have to see if you're being really really accurate which angle doesn't come off of but also how far away from the original point does it come off or if it's a thin surface how does it come out on the backside you may have other set ups coming there when you look at like a leaf in the sunshine you've got a lot of the energy bounces off the shiny top face but a lot of it diffuses through and comes out on the backside so these are not I not pleasantly analytically tractable things they wind up being big tables of data and on a one thing that's important to remember is when you seem like tables of data that are collected for things don't necessarily capture all of the important characteristics of the surface where if you take one of these sensors that you can capture I'll a table of data here if you did have your perfect mirror reflector it's almost certainly not going to have the exact sample exactly where you want I so but eventually data does win just as we increase resolution on things will have higher and higher resolutions for our service models I and will get closer and closer to reality for what were simulating so to go as kind of I a capsule history of computer graphics rendering van when computer graphics started off if you look in the sixties I sixties and early seventies I'm Peter graphics research focused on the hidden line problem we had I we headline oriented displays either true vector displays where like the old I I've I've video game arcade games like outside I'm blanking out now yelling asteroids best example I better actually drawn by raster beams moving around where they really are true line displays there's no raster there's no AG leasing I all the different games like that high were white the early in the earliest computer graphics systems were basically like that with their vector displays and once people learn how to draw figured out all but the basic projective math to say alright I've got my cube here you know I want it to look like that but when I drive I've got back on there how do we figure out which lines that we're going to be a race I and that was you know an occupied research for awhile to figure out effective ways to do that I've without spending at the time the scary divide costs for different things and you get lots of interesting %HESITATION work being going on but when we've actually got raster displays where we could fill the mid course at that point people filled in there this service is the cute they're all grayscale at that time so you can draw Cuban say well this will be the white faces will be the dark face by that was neat at the time but that was not sort of what things look like in reality so people started taking the steps that they could do to try and say what we need to do to make this more approximate what we see with our eyes and this is been a path that's been driven probably more than half by sort of ad hoc approaches about just well what's what's reasonably easy for us to do that gets a somewhat closer to it while there's also been sort of a parallel path of saying well what's the physics actually doing how do we make an actual solution for it I am so the earliest things that got added to the sheeting model Peter graphics wise if we assume that there's going to be a light that's at some point in the beginning that you would even be local you just say light is coming in from this direction so we want to be able to say what color or what she'd shoot each individual service be based on where that white some so you got the obvious thing is that if it's not facing the white no light hits it and you would draw black so the question about things that are directly facing the White so if you've got like coming in if you have a surplus simply be perpendicular to it you make that your brightest color you got a surface that's implenia along with it it gets no like make that zero so you got some curve that goes between it to say help write something I'd be and it turns out that that's a fairly straight forward bit of math solve where you have light coming in at a certain angle you got the normal to the surface the amount of light that would strike a little surface there is proportional to the cosine of this angle and that's actually that's not an approximation that's actually bit of ground truth I if you've got the light coming in and you've got something coming at this angle a surface that's count the number of race that go in on something catching four of them directly turning it down only covering two two spaces there all that actually works out correct and this is the basis for a lot of the a lot of the real calculations for light transport not a hack actually part of real proper physics measuring so what you got that basic approach you go back to your queue and you get your light coming in and you've got a brighter face a brighter face a darker face and the faces away from it are completely black and that most people say well we don't usually see things like that so now we get into the fudging in and you say well let's just brighten everything up a little bit will add an ambient term so you sort of just add this minimum level to everything on the backside and that helps a little bit if you got a Cuban everything looks pretty much great because it's a constant color just on I the side that you might not see over there but if you got something more complex everything that's not facing away from the light winds up being the same color and it's clearly not correct it's not what you'd like but it was all that seemed reasonable to do at the time the next step was to start looking at surfaces that are more than these perfectly diffuse reflectors if you make if you model your cube like this it looks kind of like it was maybe carved out a chalk I and it could be a decent representation of that but very few of the services that we see around us are really that simple most things have some kind of a shiner highlight on as we look around he could see reflections and highlights on on all sorts of things in the obvious bits of metal and plastic little things that you might holding your hand I can look at all these different shines in reflections on the plastic that I'm holding here now the observation was made that the highlights on most objects that work completely mirrors they tended to be something like bright hot spot like if you had I if you had your spear here you would have a bright hot spot the kind of faded a little bit around there and just by squad looking at that and saying well you know what could we do that would be kind of like that the observation was made that well if you take this sort of co sign arrangement here this makes this nice broad fall off it makes a I am you know over the entire surface of the sphere coming from that it'll fade off till halfway around the light but if you wanted something that was really tight I thought was well we can just take this value and reads it to a higher power we could just take this and go you know square eight cubic take it to that the twentieth power which can be done effectively mathematically quite cheaply this has no basis in physical reality at all this is a completely ad hoc approach up but it worked out okay and this is what died I mean the form lighting model was about where separated into your diffuse lighting which is I more or less what color the services and then your specular lighting which is what the highlights are going to look like so you had this other value to to play around with and that was that the specular power and nowadays I I regret using that in my terminology where we have power maps and nobody understands what those are they they relate to that I know the specular exponent what you're going to take something to a power of two to tighten it the better terminology that used more often now is a roughness map where you have a mapping and you also do it in logarithmic space rather than linear but more last that still today when a lot of graphics involves is you gotta roughness parameter which affects this exponent that you take I've this extra vector to generate your specular highlights for but again it was I it would make so if you're rendering your cube and you get the right the light at the right angle like if I'm looking at this year and the lights over here no hits that if that's at that right reflection angle then you'll get a nice bright shade on there that flat surface will catch the light and it will go into at you and that would be looked at as a as a real advance for the rendering so you got something that looks diffuse but when it moves it when it moves into the light it kind of catches a flash of light and fades out so the facets on these solid shaded models started looking better now what I Nixon the people wanted to do is okay we've we've got enough cubes and tetrahedra ends and I don't like it he grins and whatever so we want to start making things that that look more realistic we need to have a teapot you know we need to have a curved surface in some way so you make some curved surface likeness there was a lot of work in the early days on directly rasta rising curved surfaces drawing them directly bite all the real time graphics almost all of it has been a matter of turning your curved surfaces into approximations with flat surfaces so you got something that is theoretically occurred a curve but really a bunch of bass at some so if you applied by the lighting model there to it see all of these facets stands out as like okay you just carved this as you've carved this out with all these flat plains added doesn't fool you into thinking that this is smooth curved object so the next step in graphics that went on was adding the interpolation across I no across that river taxes where instead of calculating a value for a face you calculate it forgiven vertex for one corner and then you just average you interpolated cross there so that a point here is going to be some average between three or four of the points that make it up I and that works surprisingly well I if you're looking get added a few surface it works out I just about as good as you'd like there are some minor artifacts culled mock bands that you get as you if it changes too much but if you're tessellations okay that works out alright it works out less well with the specular highlights and the reason is that I your specular highlight if you've got I it might show up like you're suppose to have some hot spot right here in the middle of a surface if you calculated that the outside this is going to be almost zero for the specular almost zero and when you interpolated cross it it's gonna have nothing you're just not going to see it you only see a highlight when the specular comes up at the at the very edges and this is what still to this day sort of the standard OpenGL shading modeling Perot shading I with calculations at the vertex is interpolating the colors or parameters across it so this model is still with us to this day for a lot of quick I stopped if not visual stimulation oriented if you just write something using lighting with OpenGL that's the model that you get if you turn on specular highlights I in graphics ray care more about visual quality what what started happening was interpolating not the color across it but interpolating been normal sort of the curvature across each point and then applying the lighting model at every pixel and at the time this is this was like a flagrant use of processing power because like okay these calculations are expensive we have to do these distance calculations dot products are exponential power stuff and when you just do it at each vertex on your cube okay so you've got you got a handful of vertex is that you need to calculate but even on an old school display you would have hundreds of thousands of pixels and so if you're drawing that they're going from doing this media a few hundred times or a few thousand times to hundreds of thousands of times foreseen was the a large use of additional processing power but it got you the good looking areas where you could have a highlight that that looked about like it should moving across the surface or sitting on the floor looking stable there she moved around our people have been in following PC graphics for the last couple decades we've seen games that I hear they do not have interpolation the different ways where the lighting would change dramatically we always had the problem of densely tessellated characters are objects and then very low tessellation on the world I am the problem that you'd run into with that is that if you're applying one of these interpolations schemes to it you would have something that you could never have highlights in the middle of the service only at the corners and there were also issues with perspective math and putting that would mean that it would change is a really big polygons put by the edge of the screen I in almost all cases the way people get it and this was one of the big things that pushed me during the quake time frame to use light maps and for the first time where instead of I'd seen other games that were doing lighting at the vertex is and I didn't think it was you that wasn't good enough you couldn't get anything resembling a shadow you had all the swimming artifacts I with the lighting ages didn't give guide you what I wanted to see and while we didn't have any specular highlights it did have are these you had samples every sixteen pixels in the White maps that we interpolated across those and that gave us that do the look that was very important for it I know we can get to actually it was only all the way up to doom three where we would start doing per pixel operation I like this to to get that much better calculation so even with this level of graphics at that time eyewear you've just got sort of these phone lighting simple models acts like be I am the specular exponent of the ambient term we started to see some off line things being rendered likes of movies early work some nearly NASA promotional work that Jim Blinn did were significant and I sort of growth of all of this and we finally saw some feature theatrical films with like the last starfighter and specially tron where you would see you go back and you look at Petro on and you have a lot of these sort of Garro shaded I've solid modeled things on there with your like cycles or recognize there's and so on and they were doing something they were intelligently picking a battle that could be one at the time if you said well we have to go ahead and render photo realistic humans we were nowhere close to up to that task but we could do geometric solid models that looked good enough to show on the big screen pad that was you know that was a pretty big breakthrough and simultaneously with this there was an alternate approach to the way graphics were being drawn that I so most of the grad nearly graphics were done with rasterization where if you've got your your computer screen and you've got quiet on here I you would draw this on a computer by calculating these equations of the lines and then you would usually just kind of walk across building up your rows of pixels I the whole process of hidden surface removal is another step on top of this where if you've got lots of cubes how do you know which one draws on top of the other one and this is another thing if you look back in research from that's the seventies especially there's tons of work going on on hidden surface removal of these clever different algorithmic ways today we just kill it with a depth buffer we just throw megabytes and megabytes of memory and the problem gets solved much much easier but this path of rasterization is still with us today GPUs don't rasta rise and scanned wide order like this they play follow you know crazy winding paths to maximize memory bad with to fill up tiles arrest rising to different pieces and I rest rise alt quads at a time but it's still essentially a rasterization method where we have shapes and we figure out how to rationalize that we figure out which pixels they're going to cover and then we figure out what we want to do with them the alternate scheme which was also developed denied the later seventies is ray tracing where instead of saying alright I'm starting with my object I'm going to take these very taxes these for her taxes that are in space I'm gonna take my virtual camera and I'm going to transform their find out where they are on the screen and then fill the men retracing goes the other way where start off with your camera in space somewhere your virtual viewing screen and through that send raise out in your world and you intersect them with Cuba over here and if it hits that Cuba first it knows it didn't hit anything behind that it's got a surface point there Anticon apply whatever sheeting model it needs to the thing that ray tracing gave I mean it's radically slower like hundreds or thousands of times slower than rasterization if you're doing just the most straightforward thing if you just want to draw that cube could draw the same thing with rasterization or ray tracing it's just going to be a thousand times slower with ray tracing but it allowed a couple things that were either very difficult or impossible to do properly with rasterization and the thing that you would always see and ray tracing demo is is your shiny reflective spears so you got a little chrome ball and the fact that you could see the world reflected into it and then back in here I was the thing that ray tracing could do that rasterization couldn't do really worth a damn at all menu approximated with environment maps and different things but I for reflections and for refraction doing those things properly ray tracing was it was really the only good solution but it wasn't practical even for most offline work there are I I can remember looking old research papers and things that are run on deck VAX computers and they talk about the number of hours to render these really trivial scenes just you know a few boxes and now I maybe a spear sitting there at the idea of rendering my complete worlds with it was it was fantasy at the time but it did address some of those problems for the first time with reflection and refraction and it also much more elegantly solved shadows which all of the stuff talking about surface interactions and I'd feel finding out what you get with the light that kind of Dodge is one of the really hard problems which is saying that well the light a light obviously doesn't reach through things if you transform something up here and you transform another another surface down here in the lights up here they should be in shadow because it's blocked by this but that turns out to be not be a particularly trivial thing to resolve it's basically the same problem of how you view something from your point of view but viewed from the lights point of view and that can mean that well if every light in your scene has to do similar rate a similar rendering process to what your view does I and possibly harder because they're on the directional lights in many different cases and it's just a tough problem and as with so many things there's a lot of wonderful research in the seventies and eighties going through about how you do shadows effectively with these different analytics solutions in the end we had a brief period where stencil volumes were an effective way to do things but now it's essentially all shadow ball eyeshadow buffers where we really do take every light rendered image from their scene add use that too back project on to their to figure things out but that was one thing that ray tracing had an elegant solution forget if you're already a thousand times lower who cares if you're another factor of two or three slower for every point you hit you go ahead and say about my light up here all trace to the white or two however many lights I've got and if there's something it blocks it then that's gonna be shadowed by can take it out so retracing always had this I this much clearer abstraction of what you're doing it's easy to tell that you're sending out a little array you hit something you determine whether you hit all the other lights were few bouncer refracted to something else so it's always been easy and clear it's just had this thousand times slower problem to deal with so the advances that were being made on graphics I kind of after this early age focused on the changes in what you can do with the surfaces as the first obvious thing and a lot of these were driven by sort of artistic and aesthetic condition concerns wary we got if you pull up a three D. rendering program if you look at their material stuff there's a whole page full of option things that you can tweak knobs you can turn check boxes you can set and each of these had some use case where somebody wanted to this because it made their image generally look a certain way that they wanted very rarely wear these things driven by physically correct rendering I and there is a huge plethora of these things that came out every different program had a different set of options you always had this fall back of you got your diffuse some colors your specular color your roughness this basic Phong shading model has persists to this day but now we have a ton of other things that we can I we can tag on there things there subsurface approximates gathering approximations brindell lighting I different frequency response all I mean I on surfaces is like some of the things do have physical basis to them I am like one obvious thing the for now a fact is the effect that as you get more and more glancing to something the reflection gets stronger and stronger and you see this this is what makes water glass look like water in a glass if you look straight at them you pretty much see straight through them without a whole lot of reflection but as you get more and more edge on even a service like this where when I'm looking at this at this angle here I've got a very very strong clear sense of the slightly wavy reflection of that white line there while if I look at it right here it barely visible so that's a physical effect in reality that you can work through the real physics equations of why this happens but people again sort of called up the trusty raise a cosine to a power and it sort of looks like what we want when regarding a couple vectors together I so that has that's something that's based on plausible physics but generally only roughly approximated there are other things like that with I like a change in some battles get their metallic look because they slightly change colors as they get towards grazing angle so again you can calculate the real physics for that you can just find it kind of say well this color sort of changes to this color at the edges and start interpolating between them I but Watson lots of good work and lots of it I you know lots of high budget movies and so on were built with these sort of very adhoc techniques I but sort of in parallel with this the other big revolution that was happening was global light transport global illumination that comes back to that whole half of the NBA term this sense that obviously where okay if I'm right here the lights are only directly hitting the outside the back of my hand has no direct view to any white but it's still quite bright and clearly illuminated it's bright because all those lights hit this white white board bounce off of that and wind up writing my that my hand from the back and you can see like color changes like if I move up here where it's come mostly covered by the blue marker on there they'll be blue tends to it and this this recognition that so much of what we consider important the visual field is actually in direct it's not just a matter of here's the white here's the surface what's the reaction as we come back to how much of the white gets bounced around and there's a there's a term called the albedo of the surface which is what fraction of the light gets reflected verses absorbed and there's some tricky terminology with this because you can have either the total solar albedo where you talk about how much energy comes off of the side of this is used for climate modeling in some remote imaging and things like this where you matter bite I I but you've also been then got the visible albedo which for rendering is what we care about and the point is that the boom the best reflectors your chromosphere that's mirrored or you're white piece of chalk or your freshly driven snow those can reflect ninety if percent of the light while your darkest surfaces your lump of black coal or I asphalt in some cases might only reflect five percent but when when you're reflecting ninety percent of the white what that means is that if you're in a room that has I mostly white surfaces a single bit of light coming out of your lady better might bounce around a dozen times before it finally gets absorbed so we could take a very complex path before winds up getting to your eye and this is why we could have cases like a I a dark room illuminated only through the crack under the door but you could still wind up looking around even around corners you can go into the closet in the dark room illuminated under the keyhole and still find things somewhat lit and that's because of this many bouncing past the light can take from the lady better coming around to what actually gets to your eye and this turns out to be a really frighteningly I complex and expensive problem to solve are properly the first sets of attempts at this I've dealt with radiosity approaches and a lot of this was driven by I engineering things beyond just making pictures because you would talk about things like heat management if you have a certain amount of energy coming in here how hot is something going to get and what's the hardest part gonna be because that matters for a lot of engineering terms so you can do things like to make a I am make a complex surface here and say energy is coming in here how much of this energy makes its way here here here and it's not just a matter of what that's basic geometry calculations to say how much of this is directly been impinging on that surface what gets complicated that if you say well this reflects fifty percent of its light and that fifty percent goes all of these different ones here add this one perplexed fifty percent that goes to all the ones here and you know in theory you go if you're doing everything floating point back to keep saying you could bounce a hundred times and say you get well point oh oh oh one percent winds up coming back ought to another spot at some point you just say it's converged well enough the solution is not going to change much on that I no matter how many more bouts is that you do so the radiosity solutions work by creating this giant linear algebra matrix of can I coefficients where you say you identify all of your surfaces and you say how much can what form factor what fraction of the energy goes to all of the other different surfaces and any maybe solving this ten thousand by ten thousand matrix and there were you know there's a lot of work on the optimizations that you that go into solving this more effectively I. N. but there are two reasons why radiosity is gone around not a particularly relevant technique for computer graphics anymore one aspect that it sort of glossed over why is the notion of occlusion where if you've got a surface if this goes out here and you go around the dark corner alright we've got this surface here it's clear that they can't see the surface at all I see the service the service part of this service your fraction of it and I can see an even smaller part of this service over here so you have to calculate these occlusion terms where you're saying each one each service unless you're in your know your deformed stretched icasi Hedren or some I no service some I solid that has no convex no con cavities inside it you're going to have these bodies aspects of occlusion and this becomes a very very difficult thing to solve completely analytically if you're trying to stay in just analytic world and you I you try to solve well okay we have this surface occluding the surplus and that another surprise here and other service here it's a potentially visible set problem I want every poly gone and it's a it's an analytic nightmare so you wind up solving this by approximating you just say alright I'm gonna surface here I'll throw a bunch of raised to test out here and all through twenty raise out of ten of them get through I'll say on fifty percent occluded now a purist Wold will start blanching and saying we are but there's that's random there's this random tests you might be miss estimating there could be pathological cases I embarrassed you know there's some truth to that anytime you're sampling things they're sampling cases that they can turn out pathological but the other side of that then goes it's like well weird were tracing razor I've we have another technique that involves lots of tracing raise I income about it from a different route which is to say well let's start with ray tracing and let's try and solve the global illumination problem using nothing but ray tracing which leads to path tracing so you could make a rendering solution rendering program where you start with your light emitter you throw photons out in all directions and you have QB here and somewhere you have your eye you will get a physically accurate images if you pro random race pick a random direction it goes down someone go off here someone go up here but eventually some of them wind up getting a surface and that based on what that surface is determine which direction the light goes out going to be random ingin your your perfect reflector would not be read it would go off in exactly the perfect reflection direction all other materials will throw lighted essentially all direction but with different distribution they'll be more biased towards the reflection direction they'll be a chance that they go everywhere so one of your billions of light rays goes out hits there it decides it's going to reflect up another one goes out it's here it's gonna reflect over but eventually some ray is going to come down here a point here and reflected exactly the direction that goes over and hits the surface of your eye which the lands can then focus into something that you can perceive and this is has interesting biological side to it by the larger and I is the more light it come can collect which is why animals that will generally hunt at night can have larger eyes larger openings into their I I am white telescopes get bigger to see more you can just this is what's happening in reality zillions and zillions of photons come off they bounce around and eventually some tiny fraction of them get the lens of your ire your detector or whatever you're using and can be resolved into an image so you can make an image like this people have done it it is extraordinarily inefficient I've but you can solve everything with this is a complete an accurate salute as accurate as your %HESITATION as your analysis of what the lights distribution is and what the service is just these are and be as good as that I could have your you know your extra surface appear where you hit the ceiling you bounce back down it hit a wall over here you bounce back over and then eventually make your way to the I and you start thinking well you could have ten balances going in a random direction in your eye is only some handful of millimeters across are but you're projecting an area the size how many traces do you have to do we have to do billions and billions and you wind up with a very noisy image at that but if you get enough of them this would come out with the right solution trace array it either gets absorbed work reflects into a different way or transmits through it you got this whole the model that you use the F. bidirectional subsurface scattering it I am review should function so it's accurate is that is determines what happens to the lights could have models of the lights are the standards like I yes light tables that have I know those particular light you could look up what's the distribution of photons that come off of them you could look it up for all the different ones and as good as the data is high your simulation could beam as good as the guard as good as what you feed it I but it's hopelessly hopelessly inefficient what we wind up doing in different ways that can be reasonable approximations are stead of tracing throwing grease out from the light I which I mostly go to go nowhere near what you want you can reverse the trace and go from here I like in the kind of classic retracing go to the surface and then you start getting into the cases where one of the keys one of the sort of buzz words in high end rendering is whether render is biased a biased renderer is not necessarily perfect physics but it's almost be do it because it's going to be a lot faster like the standard thing that you do if you don't like being a biased render you say well I have all these directions that I could go to the world I could go up to the ceiling I could go down to the floor I know I got all these lights appear so I'm gonna send most of my raise towards the lights because those are almost certainly going to be the things that really make a difference so you go you hit your point and to say trace against every light you know you got three lights going here run a trace up against them check for a clue her solid things blocking it off and then you start throwing random amounts of raise a different direction you can be smart and base it on what the character of the surface is I am you know we've I got again comes out these route distribution functions where you could have raised where it's more likely that if like comes in this way it's more likely that it's going to make it out toward your eye so it makes sense to sample that more often and there is tons of work going on to this day this is sort of where the active state of the art of graphics rendering is where you how you optimize this path tracing to be more efficient in different cases but it is always then you're making your approximations on what you want to do a because you can make but the problem with this is if you have I if you buy if you're biased in your tree specifically to certain whites there could be odd combinations of surfaces here like you might have a surface here which is slightly a missive and if you want it hitting that because you were tracing toward the light that's gonna get over represented based on you know versus something that's over here that wasn't in the direction of one of the lights but this approach you know it pretty much works we do I like for the baking in it tech five we have a very primitive lighting solution because even though we do it off line I we have today the surface area of one of the maps in rage is about as much as the pixel they go into a feature film and we have turn around time so clearly we can't do these billions of ray traces for every what would be a framework that we feel we have to keep these down some credible about of time so what we do is one harassed rising a surface we don't even have the viewer at all we're doing a view independent approach for the global illumination and again the terminologies problematic because we have radiosity as terminology in a lot of places is a synonym for global illumination technically it's not it shouldn't be that way may we have a visualizer called rad preview even though it it does not do a matrix calculation for radiosity at all it's I know it is based on this moreover tracing approach so we get our services we look at all the lights that we think should be affecting us we traced to them to get by our shadows and sample them to make soft shadows in fact that's another important thing are the way you get a soft shadow is if you've got a surface and you've got an object that's gonna cast a shadow if you have if you have a point light source and so was nothing but a teeny tiny point that all the energy came out of then you would have a hard shadow age would look like doom three I am where you just have you got fully illuminated and then fully shadowed in reality there's no such thing as a point light source and this is an important I'm portant thing to realize I everything even if you look at a white ball the dangling incandescent light ball the photons are actually coming out not off of a point but often a little zigzag the film that that's insight that it has an area of the photons come off distributed from that area now the sharpness of the shadow depends on the ratio of the area of that a better to the distance that it's going across when you have a great big broad fluorescent light assembly you've got a small include her here everything is going to be let some degree that you have so in this case you might have only the very smallest area there that would be solved completely shadow but as you move over you start to build a seat part of the White so it gets brighter and brighter until you get to the point over here where you can see the entire light emitter so we have I to get the soft shadows in rage as I am and while so what have you looked at the original the earlier quakes there were soft shadows in there but they were a matter of calculating saw shadows they were because we made a hard shadow calculation and that we interpolated between it which is why you got into the blurry stair step the edges there I've Vortec five we actually send a number of shadow samples and this is one of those things that gets into performance trade offs where if a designer set a very large area for a light source then it will have you'll have a very broad area of changing shadow resolution and if you only put sixteen tests to it that means you only have the possibility of sixteen bands of different lighting that's in the best case if it comes out exactly sort of pure samples where they do their best good I edits it's completely possible to have if you got a broad area light source to meet hundreds of samples for every pixel determined how bright that should be and they can get it can get worse in a lot of cases a lot of offline rendering they use thousands of samples per I per fragment when you get into the global illumination so what we do from the direct lighting okay obviously the biased I have lighting approach their bees we sample directly to the lights but then we send out random raise from the surface to see what else it hits and when he goes out and gets the surface up here and we apply a simplified version of the lighting to that we don't do all the full soft shadows but we do basic I've whiting approaches I we've had options to do multiple additional bounces bite you know this is what we live with is some approach of sampling the global environment and we don't do it lots for each pixel what we wind up doing is I wait throws one or a few samples in a different direction and then when we average them for this pixel we average over a broader range of cels and these the types of trade offs that everybody doing rendering makes different traits like this where they I you decide what you think is most important how much time you can afford to spend on things and you can have you make your choices and you and you live with them after that %HESITATION but we know doing it right is just a matter of throwing billions of raise in an ideal case you have to throw lots and lots into the environment we can make decent approximations now bites I've we're gonna soak up all the additional computing power that can be given like one of the flaws in the offline rendering world is that I've yet frames will always take a half hour to render in those studios the more power they get just the more things that they add to it I there's hope that that that's not a wand nature that I that we are getting faster turnarounds kind of like a piece of hard drive I hard drive size verses usage but it does seem likely that the path forward is lots and lots of ray's physically accurate material I definitions and approaches that are approximations of the sampling of path tracing we can do there some meat demo's going on are going around today I like the brigade path tracing demo which is real time %HESITATION it's doing simple path tracing from sort of parallel outdoor light and it's it's noisy and physically as it comes in but you can stop and watch it kind of come in more crisply and eventually you this is going to be the way things go eyes the way we're gonna be rendering but we still have I immediate couple orders of magnitude before it's really competitive I think one more order of magnitude performance and you'll start seeing it used for some real things but it's still you have to have a good reason to step away from rasterization but probably when we get two orders of magnitude then you start seeing it as one of the more general tools and the reason that it's winning in the offline world even though it still slower people still care about how long the rendering stake even if you're making at a feature film or TV commercial it matters for your iteration time by the but since it is that you get more out of this being understandable with rasterization environment maps shadow maps they're all these noms date people just look the best people know what they mean by ninety percent of the people working in visual I I in computer graphics if they have they have these things that they know push this this way and it kind of does something but it's a lot of black magic and a lot of things they're just not at all physically plausible and this is one of the things that I've been working with the artists and here in the last several months start moving us towards this more physically based sense of things where if you just use your standard diffuse specular roughness you can have materials just make no sense at all in the real world you can have things that reflect more energy than cumbia and when you've got a bright if you celebrate specular I am and there's that the real step that we've had to make education wise is treating these maps not just a something that you painted Photoshop but how you define the materials that are there where it shouldn't be that if you're looking at something of the belt buckle you say okay this is metal it's gonna have a high specular it's gonna have a low diffuse specular may have color it it it's going to have a high power a low roughness depending on how your for Billy to get because that's what it is but far too often in the over the past decade in computer read games especially are the maps that have been fed into these things that if you snap specular maps for their Gloucester roughness or whatever you turn bad I there things that are painted in where a lot of times you'd see a specular mapper yeah you take your diffuse mapping you kind of monochrome Eisen's baby color shifted you stick it into the yeah I into the specular and you wind up with things that emit yes it makes parts of it shiny and parts of it not shiny but some of the things that I don't actually think that there is a physical material that exist that has a red specular reflection color I mean maybe there is but it's certainly not comment you know specular colors are are generally white except for battles I which could be the color of the base surface I so there's the biggest thing that's gonna be happening for making games look better is really not advancing the graphics that are still so it's the yeah I it's a matter of getting materials that actually makes sense once you're there then you can start improving you're improving the things that you do with adding your better global light transfer word I've all the other cases there at one more thing before I can offer the time warning here I so that the cost of all of this billions and billions of ray's one technique that has that's gotten a lot of currency in recent years is I ambient occlusion now to explain what ambient occlusion is it's another one of those great big hacks but it works you know useful way in its use of standard fare and a lot of off line work so if you have a I UN objects that's got some concavity here and you've got the light shining on it from here so you light it all up in an ideal world you'd be doing all of this path tracing it and you would say that okay some of the rays hit here they bounce here they bounce around it to hear some of them go up here here here and get into that so the path the tortuous path that light can take to get into their that's what you really want to deal with if you got your white surface there you might need to take trace ten bounces from thousands and thousands of things the observation that ambient occlusion is based on is that when something has other things very close to it it is very likely to be I not as bright as things that do not have to his next to it if you got a flat surface and your let you know there's nothing that's going to be braided that's taking anything away from it but if you have a flat surface that you hasn't a clue her here this area right here it might be directly seeing the light I edit my PC everything in this part of the hemisphere a part of it's going to be hitting this and some of that may be going and seeing the light some of maybe bouncing in different directions ambient occlusion all it does is incentive sampling the whole world examples just small area around the point that you're working with I and importantly it perhaps even more importantly than scope of what it sampling when it hits things it doesn't worry about the surface bottle it doesn't run I will be RD effort BR assist yet whatever I am all it does is say either I hit something close or I didn't hit something and maybe look keep track of how far away it is and if you get something like this where okay there some light coming in here I can see this but I trace out and ninety percent of everything around me is hitting something else sort of close so based on that I'm going to darken it down I just on the assumption that if I didn't run a global illumination I traced through all of this that it would come out and say that I'm not as bright as something that's next to be that's you know that's open so something out here that'll get the full value of whatever calculates and as you move towards here some of it's starting to get darker until you move all the way in here where almost all of it and it's it's a very very crude approximation of just assuming that whatever it hits isn't going to be bright and you can break that by having here cases where you know if you had if the light was coming in right here where it's directly illuminating all of that and if that was a white surface you could have more light coming down under there rather than less indeed occlusion would say Scott nearby things it should always be last bite you could actually be getting more light from the global illumination in those cases and I just one in a long line of all of these approximations that we do but the takeaway point as we know what we should do we know we we would do if we had infinite computing power to go with that so all the things now are approximations onto it ways that we can model our data ways that we can reduce our number of traces and optimizations in the code path to make things go faster and there's lots of work going on with GPU accelerated rate tracing gets on the caustic graphics work for us optimizing get its mother ways I am and there's lots of active research going on about what corners can you cut on it it's interesting because again we know what the right way zillions of photons coming out collective alright you're the lens of your eye and sort of make an image from that but it's going to be research for the coming decade or more as we can't work out what the very best approximations so are so I read a little bit over my one hour but I could start taking questions now so we get the microphone their arms until about five to seven years ago there was a every year an obvious increase and realism and offline rendering for especially movies and I'm wondering since a lot of the things you mentioned here have been around for as long as I can remember in the old fray and all that decades ago %HESITATION what is the main driver of that increase in in visual fidelity your real is not in our recent years so a couple factors one is I actually getting smarter about the materials where these I you can throw in all of this light transports stop it if you don't have good materials for it it won't matter you'll still get non realistic images so better data collections of the laser scanning the different things that let us get really good material qualities that's been one factor but probably the biggest factor is just been people being willing to throw that much more processing power at things I appear to go ahead and instead of letting these early cases where could take days to render an image that's never gonna get used in production and all you do is see you know see some of the images and like academic research and the problem with that is while some of the academic research would get the formulas right they wouldn't have the data right to go with it where if you've got it covered programmer if you wind up with I you know that the programmer the graphics researcher allied building the test scene for it it's probably not going to be a particularly good bottle of the world it's gonna have to many spiritual callous simplifications at at edges won't be I like what you go to a movie studio and they'll get all the crime and the Dixon I the dings and everything that that would make it feel like a real live digs real live again world so I think those are really the two things materials and that largely getting into the hands making it reasonable for the people that are gonna put the level of crafted detail that it needs to represent the world make it feasible for them to use your motivation out for educating the artists adhered to make it wife I think if necessary I think that it's I if you're not getting with physical rendering now you're going to be left behind as an industry I've there's and there's been big it's been interesting watching the off line world where you had sort that the masters of their domain at Pixar they've because they had the very best in process and technology for a long time they were sort of stragglers to adopt many of the things with ray tracing and physically based rendering bikes I you know they've come around for the most part now still using the right tool at the right time bite I can't think of many good arguments for not using physically plausible materials I don't think that there are artistic gains to be had by not doing it and there's all sorts of mine fields where you can mess yourself up yeah the very latest versions of OpenGL support excellent Technion %HESITATION fragment shaders and one of the things that I'm curious about is why you don't use procedural graphics and procedural geometry more than you do okay so procedural I procedural graphics has been die you know the wave of the future for the last twenty years and I think that I I actually have a fairly strong %HESITATION and sound argument philosophical stance against this where in the end procedural data is is quirky hard to deal with datacom and one of the things that we are continuing to get more and more obvious space you know the storage that we can get for things so while you can always pick out some niche market where you're you are going to be extremely constrained on %HESITATION on your space and you think what mobile should abandon baby the space were procedural stuff comes into its own bye dear that's ramping through all the storage space is right for everything that it's really not you know it all the standard methods are going on so I it's not a particular it's a good tool for making programmers bite I when you wanna put it into the hands of the eye that the people that are going to my if you're modeling the real world you laser scanned everything you go and say I'm gonna scanned this room in a bit of a terabyte of data and I'll just render that is on the north west point cloud and that's that's credible even it's not we can't ship a game like that yet but that's still within sight of something that we could do and if you want to give it to an artist to create something then they're largely going to be compositing together different things and procedural sources you are you using for your clouds in your smoke particle things like that but I know this was this was Pixar's can't for a long time about doing your they would create with live with procedures analytic procedures rather than textures and back way lost it was really pretty conclusive that nobody wants to do that they want to throw twenty layers of effective painting on top of things and you can still come up with use cases for it but it adds a lot of complexity yet I have for you know for a win that outside of poster child cases we isn't there so %HESITATION freer offline rendering have you ever considered using progressive photon mapping techniques never had a chance to talk with us Henrik one Jensen about so I wrote I photon mapping version for our our system that there's an interesting a really interesting aspect of this where I am so fundamental aspect of global illumination is that there's no difference between a light emitter and a light reflector where you have to look at saying the photons that come off of the servers are just as good as the photons that come off of that white I am and when you when you calculate through when you make a photon map for something you figure out how many photojournalists ended the world I you create a map of them the ad you I use that as an accelerator for determining your your I. global illumination solution for each point the problem that I ran into wise while that works fine for a a single serve character of a scene for indoor seemed I've found photon mapping to be pretty effective in a lot of ways I mean you still have all the problems of %HESITATION where you white upsetting things bleed throughs in some cases and they're but they're manageable problems but when I'd ran some numbers I realized that I if you're calculating an outdoor area the amount of light that falls on like one eight half by eleven sheet of paper just pulling it out in the sun all the sudden that surface has all of the photons the same amount of photons come out of a hundred watt incandescent light bulb and you start saying well we have acres and acres of surfaces out here and course where you were stealing everything down so it still fits with lately did not get to any of my output monitors gamma correction all that stuff I I tell me we we have all these tax to kind of normalizing but I found it to be I it in the situation where you had a bright outdoor area and then a dimmer indoor area you had to have so many photons in the outside to make the bed Padiham one come out reasonably that it became pretty prohibitive the other reason that we don't do photon maps is that it requires the sequencing where that that I think about distributed ray tracing and that the path tracing I its purest form it's completely embarrassingly parallel any surface can be done at the at any time because we run on multi threads of multi core processors and multiple systems in a cluster and if you want to do something with an intermediate step like a photon map you have to build the photon mapped in some hopefully parallel way and then transfer it to everything else and we had my very first global illumination solution in the early days of rage was GPU accelerated by rendered little hemispheres on the GPU and built up a I built up a low resolution mega texture of the world use that global domination which as it was I reminiscent of a photon map and it was it was just one of those things that if practiced turned out to really be kind of a pain and when we went to a a completely separable solution a lot of problem stop happening I feel that I I I it was interesting implementing the photon maps stopped going to review the cases and it's certainly a valid direction right now but I think that the yeah I am I in a lot of cases that the necessity to Jenna rate that ahead of time is a little bit of a hazard for implementation in a lot of parallel cases for running on a single system if you know you're going to just plow through it all there I it it's got a lot of benefits it just hurts a little more in a cluster a high so you are talked a lot about the geometry the retracing our sort of stuff I was just curious you talk about how you manage these like representations of specifically things like fluorescent okay yeah so I can get another one of my topics I was on my list I did have time to go through I'm so we get by the classical computer graphics light is you wind up with three months three models of light you got a point light a spotlight the parallel life and those are our sort of beef Y. and lights in the editor the hive we ate we augment the point lights by giving them or area radio so we get the soft shadows and so we got the distributed ray tracing to that the the biggest problem though is that these are all of our lights are completely physically implausible because they're physically bounded with the exception of the parallel light and some of this is history when we go from from quake one I've you all the way up there especially doom three we built all of our lights out of I am out of textures because doom three was all dynamics we multiply two textures together where you would have a projection texture in a fall off textures we occupied this idea this physical space and not in the world which is great for for calling reasons where you could say all right in doom three we tried to say no more than three lights hitting a service because it was a linear cost every light cost more on that surface so we wound up with these lights that were very physically implausible while you can make if you're doing this multiply two textures together you could make a Gaussian fall off light which is a pleasant like to work with that is radially symmetric but most of the lights in the game wound up being our square light which is a a light that goes almost to the outside edges of this I had this text you're just beating a little better than feeding a little bit the other direction so we could get kind of about as much light as we could into the world for minimal fragment cost and unfortunately we kept those through rage as most of our I feel as our primary lifestyle and we had some our very best artists love this because it gave him total control if they would call it painting with lights so they would be able to say I want to Syria little bit brighter here so you know I move I'll use this different texture instead of the standard one on moved as are all structured so just barely goes below the floor but it has no fall off so it's gonna throw all the light into it and that is largely by the type of artistic wizardry that we need to evolve past because you will never be able to take like debaters like that and make the world feel real because the whites not real you could even have completely real materials and you could be doing with path tracing but if your light is only coming from these things that do not resemble real lights that it's never going to be bought off is real now several years ago I made a preemptive a premature evidently push towards I've physically based lighting where I was trying to set all of our lights up without using I yes light profiles which are these actual light profiles that the people that big light bulbs go and measure all of these things can get I you know the light is coming at all these different areas example points coming out of it and that's really useful although it's important to note that there are simplifications in here just like just because you see an equation doesn't mean it's true just because you see a table of data doesn't mean it's true either because you have simplifications like IE aspect or three fluorescent bulbs in not in a fixture and yes you are sampling what the light is that all of these points but really you should be getting three shadows from it rather than you know rather than one from an area light source so there's simplifications built into that but I still you know we are not currently using that are the main reason why it it fell through when I push for it originally was it comes back to the performance I do keep the build times at a certain you know at a level that they were familiar with you wound up with these lights knower extending infinitely their proper inverse square fall off lights so if you got on a level with a thousand lights in it dead in theory you're tracing a thousand traces out at a minimum to just see whether any light gets there so you you cut this down to some rational number of samples of what that means is there's lots of noise in the images and one of the battles that's been particularly hard for all the tech five stuff is trying to have a situation where the designers and artists are are willing to work with an approximation of what they are I you know what the final outcome ideas and it is you know it is just very tempting to say well I always want to look at what the final outcome ideas which means that everything is always a production quality render which means always takes forever and as you know I I keep hoping that there will be more of an acceptance of well this is roughly what it's like I can still be a figure out what my game play it rough lighting everything is but that's about all that we fight daily I don't %HESITATION taking quality material data for granted I'm curious what additional visual fidelity you gain by %HESITATION ray tracing box lock trees and then what visual sacrifices you make and what sacrifices have to make in terms of performance or to gain performance so the the question of what your retracing against his sore report Bogomil to burn the method I mean why are you can I you could rest riser retrace lots of different representations and there was lots of work that went into directly ray tracing gets curved surfaces and spears and some of the easy cases and for years I did think that ray tracing into some form of voxel space would be a I an obvious thing to do because it seems that there's you know there's wins there so it's certainly far simpler could make a more regular data structure there's there's all these things but it doesn't seem to be panning out that way it does seem to be that already treason will be can strangle bashes that you will decimate too wet and there certainly advantages to the the comfortable tool paths everything there it seems that's the way that history is flowing and that's probably the way it's gonna work out when we are retracing everything to a little bit yesterday on the motion blur that have the LCD screens as you I had Oakley %HESITATION getting more thoughts on if that's a solvable problem for this generation of Bihar's that's gonna take a little longer so we have an existence proof of something that's good enough I mean what valve put together by packing up the inside the Samsung displays is by is good enough if we can get ninety hertz displays that are low persistence %HESITATION that will do I you know hundred twenty would probably be better bites I had like my interlaced scheme may be a good thing to I had to kind of add on top of that if it can be done odd but I think there's there's a good prospect in the fall back plan is Ellie Ellie LCD backlight flashing so it's important and I think that I'm betting that it will be solved for serve consumer grade VR indict the not too distant future but it's like you know it's not there right now outside of valves prototype I don't know thanks for the talk %HESITATION a few years ago I read an MIT paper explaining how to compute saw shadows and what they did was %HESITATION the interplay literally between all of the parts that were leading the parts that were not met %HESITATION is not the approach it takes about a linear mapper nonlinear met between the number and the pin number and I was just hoping you could explain in detail how you calculate the intermediate levels knows okay so that does fall into the other category of large body of work of approximations that is pretty much gone and forgotten right now are saw shadows are done by sending a certain number of samples like it's sixteen by default so you send sixteen samples to different points on the white powder randomly distributed add the density of the shot it was just a fraction of them to get through so you can crank that number up in some cases for some of the I. the really broad area debtors in theory you'd want it to be two hundred fifty six sample so you can get a full range of or even more are very bright lights but we we get by with sixteen there's there's an approximation that I did on that that succumb instead of randomly setting to all points in the center of that all points across the area of the light source my default we send them across the circumference of the light which gives you know in theory can sometimes make it looked I've a square factor better but it looks bad edges so we're still treating different things on there but the bottom line it's just our many samples you throw that's the fraction it comes out things like that are going back through the history of graphics for forty years there's a ton of things that were somewhat complicated analytics solutions they've just over and over fallen to rob through force and I think that all of these things will as well you know when we when we are tracing billions of race per frame I that's when we'll be using ray tracing I don't that there can be too many other media steps to that %HESITATION %HESITATION so I know that in auto CAD and other engineering programs that's that's swords %HESITATION there are catalogs of different types of materials that you can now test the affects of different %HESITATION different things on the %HESITATION structure so on so forth of just the different kinds of materials and what my question is for you is that with trying to make your artist use more accurate materials a trying to like created a catalog textures Sir yeah so right now we are very much trying to have our our master swatch list of I know we've we need there's the clear things but okay if you're metal you're in this range of your pain you're in this range if your work here in this range asphalt having all of this say represented as these are the valid ranges of diffuse specular rough Nessim I and maps that you could have I so weird we're still working through all of that and in terms of material libraries it's it's a little frustrating when you look at whether it's three D. studio remote our I puree whatever I the materialists are usually the ad hoc collection that's accreted over a couple decades of company lifespan and they're usually not a complete consistent cohesive physically based set of materials we spent a little bit of time trying to I'd to backtrack values from one at that Materiali presets into things that we could use and it wasn't completely clear that they were that they were coming out in the right ranges so where you were building up our own set there's lots of studios doing that there are now online there are sets of the RDF measurements for a lot of materials that would be good to start %HESITATION drawing some of the materials from but there's we're still looking for okay what's the diff you specular and roughness higher values going rather than this full table of data but eventually I expect that we all will be using this is data scanned in from the real world over and over that's why chilly winds in are no se hit John thank you fixed on time 
